<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jong-Beom Jeong</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jong-Beom Jeong
                </p>
                <p>
                  I'm a Post-Doc at <a href="https://www.etri.re.kr/eng/main/main.etri">Electronics and Telecommunications Research Institute (ETRI)</a> in Daejeon, South Korea.
                  I work in the media coding research section, and our team focuses on compression and representation of Gaussian splatting. 
                </p>
                <p>
                  I did my PhD at <a href="https://www.skku.edu/eng/">Sungkyunkwan University (SKKU)</a>, where I was advised by <a href="http://mcsl.skku.edu/professor/">Prof. Eun-Seok Ryu</a>. 
                  I participated in the standardization of <a href="https://mpeg-miv.org/">ISO/IEC 23090-12 MPEG immersive video (MIV)</a>, and conducted research including 360-degree video streaming, tile-based viewport-adaptive streaming, neural radiance fields (NeRF), and 3D Gaussian splatting (3DGS).
                </p>
                <p>
                  My research focuses on photorealistic volumetric media representation. 
                  Specifically, I'm interested in media compression and streaming to achieve low-latency and high-quality media. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:jbjeong@etri.re.kr">Email</a> &nbsp;/&nbsp;
                  <a href="https://drive.google.com/file/d/1HBsj1Kop-O_fTl4kx1Rol9GgnN6XQ4NG/view?usp=drive_link">CV</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/jong-beom-jeong-6a84a8180/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=iDh5VMkAAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.researchgate.net/profile/Jong-Beom-Jeong?ev=hdr_xprf">ResearchGate</a> &nbsp;/&nbsp;
                  <a href="https://gitlab.com/MCSLJeong">Gitlab</a> &nbsp;/&nbsp;
                  <a href="https://github.com/uof4949/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/jongbeomjeong.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/jongbeomjeong.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:16px;width:100%;vertical-align:middle">
            <h2>Selected Publications</h2>
          </td>
        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr onmouseout="merf_stop()" onmouseover="merf_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='merf_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/merf_after.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/merf_before.jpg' width="160">
          </div>
          <script type="text/javascript">
            function merf_start() {
              document.getElementById('merf_image').style.opacity = "1";
            }

            function merf_stop() {
              document.getElementById('merf_image').style.opacity = "0";
            }
            merf_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://merf42.github.io/">
            <span class="papertitle">MERF: Memory-Efficient Radiance Fields for Real-time View Synthesis in Unbounded Scenes</span>
          </a>
          <br>
          <a href="https://creiser.github.io/">Christian Reiser</a>,
          <a href="https://szeliski.org/RichardSzeliski.htm">Richard Szeliski</a>,
          <a href="https://dorverbin.github.io/">Dor Verbin</a>,
          <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, <br>
          <a href="https://bmild.github.io/">Ben Mildenhall</a>,
          <a href="https://www.cvlibs.net/">Andreas Geiger</a>,
          <strong>Jonathan T. Barron</strong>,
          <a href="https://phogzone.com/">Peter Hedman</a>
          <br>
          <em>SIGGRAPH</em>, 2023
          <br>
          <a href="https://merf42.github.io/">project page</a>
          /
          <a href="https://www.youtube.com/watch?v=3EACM2JAcxc">video</a>
          /
          <a href="https://arxiv.org/abs/2302.12249">arXiv</a>
          <p></p>
          <p>
          We use volumetric rendering with a sparse 3D feature grid and 2D feature planes to do real-time view synthesis.
          </p>
        </td>
      </tr>



      <tr onmouseout="alignerf_stop()" onmouseover="alignerf_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='alignerf_image'>
              <img src='images/alignerf_after.jpg' width="160"></div>
            <img src='images/alignerf_before.jpg' width="160">
          </div>
          <script type="text/javascript">
            function alignerf_start() {
              document.getElementById('alignerf_image').style.opacity = "1";
            }

            function alignerf_stop() {
              document.getElementById('alignerf_image').style.opacity = "0";
            }
            alignerf_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <a href="https://yifanjiang19.github.io/alignerf">
            <span class="papertitle">AligNeRF: High-Fidelity Neural Radiance Fields via Alignment-Aware Training</span>
          </a>
          <br>
          <a href="https://yifanjiang.net/">Yifan Jiang</a>,
          <a href="https://phogzone.com/">Peter Hedman</a>, 
          <a href="https://bmild.github.io/">Ben Mildenhall</a>,
          <a href="https://ir1d.github.io/">Dejia Xu</a>, <br>
          <strong>Jonathan T. Barron</strong>,
          <a href="https://spark.adobe.com/page/CAdrFMJ9QeI2y/">Zhangyang Wang</a>,
          <a href="https://tianfan.info/">Tianfan Xue</a>
          <br>
          <em>CVPR</em>, 2023
          <br>
          <a href="https://yifanjiang19.github.io/alignerf">project page</a>
          /
          <a href="https://arxiv.org/abs/2211.09682">arXiv</a>
          <p></p>
          <p>
          Accounting for misalignment due to scene motion or calibration errors improves NeRF reconstruction quality.
          </p>
        </td>
      </tr>
      
  <tr onmouseout="dreamfusion_stop()" onmouseover="dreamfusion_start()"  bgcolor="#ffffd0">
    <td style="padding:16px;width:20%;vertical-align:middle">
      <div class="one">
        <div class="two" id='dreamfusion_image'><video  width=100% height=100% muted autoplay loop>
        <source src="images/dreamfusion.mp4" type="video/mp4">
        Your browser does not support the video tag.
        </video></div>
        <img src='images/dreamfusion.jpg' width="160">
      </div>
      <script type="text/javascript">
        function dreamfusion_start() {
          document.getElementById('dreamfusion_image').style.opacity = "1";
        }

        function dreamfusion_stop() {
          document.getElementById('dreamfusion_image').style.opacity = "0";
        }
        dreamfusion_stop()
      </script>
    </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <a href="https://dreamfusion3d.github.io/">
        <span class="papertitle">DreamFusion: Text-to-3D using 2D Diffusion</span>
      </a>
      <br>
      <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>,
      <a href="https://www.ajayj.com/">Ajay Jain</a>,
      <strong>Jonathan T. Barron</strong>,
      <a href="https://bmild.github.io/">Ben Mildenhall</a>
      <br>
      <em>ICLR</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Outstanding Paper Award)</strong></font>
      <br>
      <a href="https://dreamfusion3d.github.io/">project page</a>
      /
      <a href="https://arxiv.org/abs/2209.14988">arXiv</a>
      /
      <a href="https://dreamfusion3d.github.io/gallery.html">gallery</a>
      <p></p>
      <p>
      We optimize a NeRF from scratch using a pretrained text-to-image diffusion model to do text-to-3D generative modeling.
      </p>
    </td>
  </tr>

  <tr onmouseout="guandao_stop()" onmouseover="guandao_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='guandao_image'>
        <img src='images/guandao_after.png' width="160"></div>
      <img src='images/guandao_before.png' width="160">
    </div>
    <script type="text/javascript">
      function guandao_start() {
        document.getElementById('guandao_image').style.opacity = "1";
      }

      function guandao_stop() {
        document.getElementById('guandao_image').style.opacity = "0";
      }
      guandao_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2304.14473">
      <span class="papertitle">Learning a Diffusion Prior for NeRFs</span>
    </a>
    <br>
    <a href="https://www.guandaoyang.com/">Guandao Yang</a>, 
    <a href="https://abhijitkundu.info/">Abhijit Kundu</a>, 
    <a href="https://geometry.stanford.edu/member/guibas/index.html">Leonidas J. Guibas</a>, 
    <strong>Jonathan T. Barron</strong>, 
    <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>
    <br>
    <em>ICLR Workshop</em>, 2023
    <p></p>
    <p>
      Training a diffusion model on grid-based NeRFs lets you (conditionally) sample NeRFs.
    </p>
  </td>
  </tr>

            <tr onmouseout="mira_stop()" onmouseover="mira_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='mira_image'>
                    <img src='images/mira_after.jpg' width="160"></div>
                  <img src='images/mira_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function mira_start() {
                    document.getElementById('mira_image').style.opacity = "1";
                  }

                  function mira_stop() {
                    document.getElementById('mira_image').style.opacity = "0";
                  }
                  mira_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://openreview.net/forum?id=AmPeAFzU3a4">
                  <span class="papertitle">MIRA: Mental Imagery for Robotic Affordances</span>
                </a>
                <br>
                <a href="https://yenchenlin.me/">Lin Yen-Chen</a>, 
                <a href="http://www.peteflorence.com/">Pete Florence</a>, 
                <a href="https://andyzeng.github.io/">Andy Zeng</a>, <strong>Jonathan T. Barron</strong>, 
                <a href="https://yilundu.github.io/">Yilun Du</a>,
                <a href="https://people.csail.mit.edu/weichium/">Wei-Chiu Ma</a>,
                <a href="https://anthonysimeonov.github.io/">Anthony Simeonov</a>,
                <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
                <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
                <br>
                <em>CoRL</em>, 2022
                <p></p>
                <p>
                  NeRF lets us synthesize novel orthographic views that work well with pixel-wise algorithms for robotic manipulation.
                </p>
              </td>
            </tr>		
            
            <tr onmouseout="samurai_stop()" onmouseover="samurai_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='samurai_image'>
                    <img src='images/samurai_after.jpg' width="160"></div>
                  <img src='images/samurai_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function samurai_start() {
                    document.getElementById('samurai_image').style.opacity = "1";
                  }

                  function samurai_stop() {
                    document.getElementById('samurai_image').style.opacity = "0";
                  }
                  samurai_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://markboss.me/publication/2022-samurai/">
                  <span class="papertitle">SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image Collections</span>
                </a>
                <br>
                <a href="https://markboss.me">Mark Boss</a>, 
                <a href="">Andreas Engelhardt</a>, 
                <a href="https://abhishekkar.info/">Abhishek Kar</a>, 
                <a href="http://people.csail.mit.edu/yzli/">Yuanzhen Li</a>, 
                <a href="https://deqings.github.io/">Deqing Sun</a>, 
                <strong>Jonathan T. Barron</strong>,
                <a href="https://uni-tuebingen.de/en/faculties/faculty-of-science/departments/computer-science/lehrstuehle/computergrafik/computer-graphics/staff/prof-dr-ing-hendrik-lensch/">Hendrik P. A. Lensch</a>,
                <a href="https://varunjampani.github.io">Varun Jampani</a>
                <br>
                <em>NeurIPS</em>, 2022
                <br>
                <a href="https://markboss.me/publication/2022-samurai/">project page</a> /
                <a href="https://www.youtube.com/watch?v=LlYuGDjXp-8">video</a> /
                <a href="https://arxiv.org/abs/2205.15768">arXiv</a>
                <p></p>
                <p>
  A joint optimization framework for estimating shape, BRDF, camera pose, and illumination from in-the-wild image collections.
                </p>
              </td>
            </tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a>
								<br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a>
								<br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a>
								<br>
								<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a>
								<br>
								<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
